models:

  Logistic Regression:
    C: [0.01, 0.1, 1]
    solver: ['liblinear', 'lbfgs', 'newton-cg']
    penalty: ['l2']
    class_weight: [{0: 1, 1: 5}, {0: 1, 1: 10}]
    max_iter: [5000]

  SVM:
    C: [0.01, 0.1]
    kernel: ['rbf', 'poly']
    gamma: ['auto', 'scale']
    max_iter: [5000]
    
  Decision Tree:
    max_depth: [15, 25, 35]
    criterion: ['gini', 'entropy']
    min_sample_split: [100, 200, 300]
    max_features: ['None', 5]
    class_weight: [{0: 1, 1: 7}, {0: 1, 1: 10}]

  Random Forest:
    n_estimators: [200, 400, 600]
    max_depth: [20, 30, 40]
    min_sample_split: [100, 200, 300]
    class_weight: [{0: 1, 1: 5}, {0: 1, 1: 7}, {0: 1, 1: 10}]

  LightGBM:
    n_estimators: [300, 500, 700]
    learning_rate: [0.1, 0.5]
    num_leaves: [31, 50, 80]
    max_depth: [5, 7, 11]

  XgBoost:
    n_estimators: [300, 500, 700]
    learning_rate: [0.01, 0.05, 0.1]
    max_depth: [5, 7, 11]
